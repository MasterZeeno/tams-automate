name: Automated Scraping

on:
  # Schedule the scraper to run daily at midnight (UTC)
  schedule:
    - cron: "0 0 * * *"
  
  # Allow manual triggering of the workflow
  workflow_dispatch:

jobs:
  puppeteer:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Set environment variables
        run: |
          echo "ZEE_USERNAME=${{ secrets.ZEE_USERNAME }}" >> $GITHUB_ENV
          echo "ZEE_PASSWORD=${{ secrets.ZEE_PASSWORD }}" >> $GITHUB_ENV
          echo "TAMS_BASE_URL=${{ secrets.TAMS_BASE_URL }}" >> $GITHUB_ENV
          echo "HCC_BASE_URL=${{ secrets.HCC_BASE_URL }}" >> $GITHUB_ENV

      - name: Build Docker image
        run: |
          docker build -t puppeteer-runner .

      - name: Run Puppeteer tests
        run: |
          docker run --rm puppeteer-runner

      - name: Commit and push results
        if: ${{ (github.event_name == 'schedule' || github.event_name == 'workflow_dispatch') && success() }} # Push if scheduled or manually triggered and successful
        run: |
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"
          git pull --rebase  # Prevent conflicts by pulling latest changes

          # Check if there are changes to commit
          if [ "$(git status --porcelain)" ]; then
            git add results/*.json
            git commit -m "Scraped data from $(date +"%Y-%m-%d %H:%M:%S")"
            git push
          else
            echo "No changes to commit."
          fi
